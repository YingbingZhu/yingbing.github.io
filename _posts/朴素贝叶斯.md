朴素贝叶斯原理简单，也很容易实现

在统计资料的基础上，依据某些特征，计算各个类别的概率，从而实现分类。

在大量样本下会有较好的表现，不适用于输入向量的特征条件有关联的场景。

“朴素”：特征与特征之间是独立的，互不干扰。如果特征比较多时，往往独立性的条件不重要（互相抵消），可以用朴素贝叶斯。

P（类别）为先验概率

![](机器学习/resources/D31F9326B8DCE9AD83ADCA9E0749381C.png)

应用场景：源于推理的需要，例如：通过商品的描述（特征X）来推理商品的类别（Y）。

训练的时候：得出条件概率表 
推理的时候：比较条件概率的大小 
特点：训练容易，推理难

![这里写图片描述](机器学习/resources/53CF0DBD612AF787F4D466C973AD4833.png)

拼写纠正：



垃圾邮件检测：

![](机器学习/resources/CCAAE70C98ABD004B5A9926EBE290CBC.jpg)

P(D) 这个词在邮件中出现的概率

P（D/H+) 当他是垃圾邮件时，里面是这些词的概率

![](机器学习/resources/125A448864BF54391ED7250B363A02F4.jpg)

![](机器学习/resources/7255DFEA430806A1C5F5D84E4330AC62.jpg)

单词拼写纠错：

![](机器学习/resources/1DFA5C6112CFFB12E6D397EB020C1D0A.jpg)

![](机器学习/resources/139A9CC8301F0527AABABD9B47749BF1.jpg)

### 朴素贝叶斯模型

朴素贝叶斯常用的三个模型有：

* 高斯模型：处理特征是连续型变量的情况
* 多项式模型：最常见，要求特征是离散数据
* 伯努利模型：要求特征是离散的，且为布尔类型，即true和false，或者1和0

