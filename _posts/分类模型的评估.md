一、二元分类问题
========

对于多元分类问题，在实际的处理过程中常将它们转换为多个二元分类问题解决

![](https://upload-images.jianshu.io/upload_images/13886000-c32e8235dc7a2dfb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1200)

图1

二、查准率与查全率
=========

![](https://upload-images.jianshu.io/upload_images/13886000-cfb7ab2e1ef278d5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1200)

图2

![](https://upload-images.jianshu.io/upload_images/13886000-9554ce5bcc27529c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/900)

表1

预测值等于1时，真实值等于1的概率为查准率；真实值等于1时，预测值等于1的概率为查全率。

![Precision = P(y\_i = 1 | \\hat{y}\_i = 1), Recall = P(\\hat{y}\_i = 1 | y\_i = 1) \\tag{2}](机器学习/resources/B1F85999C5E321879E0391E798A6CF7E)

三、F-score
=========

例如对于网上购物的衣服推荐，电商平台关心的是那些对衣服感兴趣的客户，希望模型对这些客户的预测都正确；而那些对衣服不感兴趣的客户，即使模型结果有较大偏差，也是可以接受的。也就是说，电商平台重视查全率，但不太关心查准率。这时就可以调低模型的预测标准，通过牺牲查准率来保证查全率。但在有的场景中，查准率才是重点。例如在实时竞价（RTB）广告行业，有3种参与者：需要在互联网上对产品做广告的商家，比如Nike；广告投放中介（DSP）；广告位提供者，比如新浪网。Nike将广告内容委托给广告投放中介A，A通过分析选定目标客户群。当目标客户访问新浪网时，A向新浪网购买广告位并将Nike广告推送给他。如果该客户点击了Nike广告，Nike会向投放中介A支付相应费用。否则，全部费用由中介A承担。那么对于广告投放中介A，它希望投放的每条广告都会被点击，但不太关心是否每个对Nike感兴趣的客户都被推送了广告。换句话说，广告投放中介更关心查准率。于是可以通过调高模型的预测标准来提高查准率，当然这时会牺牲一部分查全率。

四、总结
====

查准率、查全率和F-score是最为常用的二元分类结果评估指标。其中查准率和查全率这两个指标都只侧重于预测结果的某一个方面，并不能较全面地评价分类结果。而F-score则是更加“上层”的评估指标，它建立在前面两个指标的基础上，综合地考虑了分类结果的精确性和全面性。

从上面的讨论可以看到，这三个指标针对的是某一份给定的分类结果。但对于大多数分类模型，它们往往能产生很多份分类结果，比如对于逻辑回归，调整预测阈值可以得到不同的分类结果。也就是说，这三个指标并不能“很全面”地评估模型本身的效果，需要引入新的评估指标。

=

以逻辑回归为例，我们就可以很清楚地看到，为什么说同一个模型可以产生很多份不同的分类结果了：调整预测阈值α可以得到不同的分类结果。

二、ROC空间
=======

定义好真伪阳性率这两个评估指标后，我们考虑将它们图形化：以伪阳性率（False Positive Rate）为横轴、真阳性率（True Positive Rate）为纵轴画一个长度为1的正方形，形成所谓的ROC空间。那么对于一份预测结果，根据相应的真伪阳性率，可以将它表示为ROC空间中的一点，如图1所示。

![](https://upload-images.jianshu.io/upload_images/13886000-59918c5b1f849e49.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/542)

图1

关于ROC空间，有以下几点值得注意。

* 在ROC空间里，离左上角越近的点预测准确率越高。

三、ROC曲线和AUC
===========

如果将模型的阈值从0缓慢增加到1，并把每个阈值对应的预测结果记录在图上，就可以得到所谓的ROC曲线（接收者操作特征曲线，Receiver Operating Characteristic Curve），如图3所示。ROC曲线下的面积，如图中的灰色部分，被称为AUC。它是一个很重要的评估指标。简单来讲，AUC越大，模型的预测效果越好。

![](https://upload-images.jianshu.io/upload_images/13886000-4cbe7dbcfdad2d21.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/481)

图3

我们可以更深入地来探讨AUC所代表的意义。在抽象的数学讨论之前，先来看一个简单的直观例子：数据集里一共有4个数据，分为被记为1、2、3、4。这些数据按![y\_i](机器学习/resources/2AED4F9D43D5FFD9F1DD7F4244741DFF)的取值被分为两组：第一组包含数据1、2，即![y\_1 = y\_2 = 1](机器学习/resources/1AB1860D4BAA0CAC702E9EA7F7D4061C)；第二组包含数据3、4，即![y\_3 = y\_4 = 0](机器学习/resources/0C0B82C6CC86E583A2AD926597D1D8AC)。假设某个逻辑回归模型对它们的直接预测结果记为![P\_1,P\_2,P\_3,P\_4](机器学习/resources/5B9159216F6DA1399F5AEE4A146A1A22)，我们可以称这些结果为数据的得分。其中![P\_1 = 0.8,P\_2 = 0.4](机器学习/resources/E34D2FA2EB82EE3F2A79600F42E726D1.4)，而![P\_3 = 0.5,P\_4 = 0.1](机器学习/resources/ABB6C3469C065CEA36FD07522C276DAD.1)。所以模型阈值![\\alpha](机器学习/resources/2532CCDED34281FD26C83D233026C955)与最终预测结果所对应的真伪阳性率如表1所示。

![](https://upload-images.jianshu.io/upload_images/13886000-03bee918746f9d01.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/754)

表1

![AUC = P(\\hat{P}(y\_k = 1) \> \\hat{P}(y\_l = 1)) \\tag{4}](机器学习/resources/C88B593EE9E7213AC5AABD79AE5EBD78)

![](https://upload-images.jianshu.io/upload_images/13886000-3fd9d93ad5ff6d33.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/490)

图4

可以看到，AUC与之前定义的查准查全率不同，它的取值不依赖模型阈值α，而完全取决于模型本身。因此它可以被认为是更加全面的模型评估指标。另外，虽然传统的AUC是定义在二元分类问题上的。但如果如公式(4)那样，从概率的角度理解它，可以帮助我们将这一指标推广到更多应用场景，比如大规模推荐系统（在这些场景里，可以通过随机抽样的方式估算公式(4)的概率值，而这个概率值就是AUC）限于篇幅，具体细节这里就不做进一步展开了。