监督学习的任务就是学习一个模型，应用该模型对给定的输入预测相应的输出。

监督学习方法又可以分为生成方法（generative approach）和判别方法（discriminative approach），所生成的模型分别为生成模型和判别模型。

生成模型：由数据学习联合概率分布P(X,Y)，然后求出条件概率分布P(Y∣X)作为预测的模型

生成模型常见模型：

朴素贝叶斯（Naive Bayes）

隐马尔科夫模型（HMM）

高斯混合机其他类型混合模型（GMM）

平均单依赖估计（AODE)

LDA主题模型

限制玻尔兹曼机（RBM）

贝叶斯网络（Bayesian Networks）

隐含狄利克雷分布（Latent Dirichlet Allocation）。

判别模型：

判别方法关心的是：给定的输入X

X ，应该预测什么样的输出Y

Y。

判别模型常见模型：

线性回归（Linear Regression）

逻辑回归（Logistic Regression）

支持向量机（SVM）

传统神经网络（Traditional Neural Networks）

线性判别分析（Linear Discriminative Analysis）

条件随机场（Conditional Random Field）

集成学习（boosting）

条件随机场（Conditional random fields）

两种方法的不同：

（1）生成方法优点：

生成方法可以还原出联合概率分布$P(X，Y) $，判别方法不能。

生成方法学习收敛速度更快，即当样本容量增加时，学到的模型可以更快的收敛于真实模型。

当存在隐变量时，仍可以用生成方法，但判别方法不能用。

-生成模型的假设性更强一些，因为通常是从后验分布的角度去思考问题，通常对x的分布做了一些假设

生成模型最大化联合对数似然函数

因为生成模型对于特征的分布都做出了一定的假设（如高斯判别模型假设特征分布满足多元高斯分布），所以如果对于特征的分布估计比较正确的情况下，生成模型的速度更好准确性也更高。

-生成模型在训练数据的时候对于每一类数据的都是独立估计的（也就是每一类的参数不同），这也就说明如果有新类别加入的情况下，是不需要对原有类别进行重新训练的

-生成模型有一个大的缺点就是不能对特征进行某些预处理（如特征映射），因为预处理后的数据分布往往有了很大的变化。

（2）判别方法特点：

直接学习条件概率P(Y∣X)

P(Y∣X) 或决策函数f(X)

f(X) ，直接预测，往往学习准确率更高

由于直接学习条件概率P(Y∣X)

P(Y∣X) 或决策函数$f(X) $，可以对数据进行各种程度上的抽象、定义特征并使用特征，因此可以简化学习问题。

最大化似然函数

由生成模型可以得到判别模型，但由判别模型得不到生成模型。